{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# papeles package - institutions networks per topics\n",
    "\n",
    "In this notebook, we'll group institutions networks to particular topics extracted in [this script](https://github.com/glhuilli/papeles/blob/master/scripts/papeles%20-%20keywords%20topics%20analysis.ipynb).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from collections import Counter \n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from papeles.paper.neurips import get_key, institutions, institutions_graph\n",
    "from papeles.utils.topics import TopicPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7edf0cb47f454f9e2632488da43b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loading files', max=6086.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695446ad6fce4990952c1ac2fdbecb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loading metadata', max=6083.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# These are files with encoding issues that were not parse correctly by the pdf_parser \n",
    "SKIP_FILES = [\n",
    "    '5049-nonparametric-multi-group-membership-model-for-dynamic-networks.pdf_headers.txt',\n",
    "    '4984-cluster-trees-on-manifolds.pdf_headers.txt',\n",
    "    '5820-alternating-minimization-for-regression-problems-with-vector-valued-outputs.pdf_headers.txt',\n",
    "    '9065-visualizing-and-measuring-the-geometry-of-bert.pdf_headers.txt'\n",
    "    '4130-implicit-encoding-of-prior-probabilities-in-optimal-neural-populations.pdf_headers.txt',\n",
    "    '7118-local-aggregative-games.pdf_headers.txt'\n",
    "]\n",
    "\n",
    "NEURIPS_ANALYSIS_DATA_PATH = '/var/data/neurips_analysis'\n",
    "\n",
    "file_lines = defaultdict(list)\n",
    "for filename in tqdm(os.listdir(os.path.join(NEURIPS_ANALYSIS_DATA_PATH, 'files_headers/')), 'loading files'):\n",
    "    if filename in SKIP_FILES:\n",
    "        continue\n",
    "    with open(os.path.join(NEURIPS_ANALYSIS_DATA_PATH, './files_headers/', filename), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            file_lines[get_key(filename)].append(line.strip())\n",
    "            \n",
    "metadata_path = os.path.join(NEURIPS_ANALYSIS_DATA_PATH, 'files_metadata/')\n",
    "\n",
    "metadata = {}\n",
    "for filename in tqdm(os.listdir(metadata_path), 'loading metadata'):\n",
    "    with open(os.path.join(metadata_path, filename), 'r') as f: # open in readonly mode\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "            metadata[get_key(data['pdf_name'])] = data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and predicting topics\n",
    "\n",
    "In this analysis, I'll use only topics of 3-grams. Using 2-grams and 1-gram topics needed further manual post-processing (e.g. removing topics that were mostly about writting styles instead of research topics). \n",
    "\n",
    "For purposes of this analysis, I'll only compute the top 3 most frequent topics mentioned in abstracts per year, from 2009 to 2019. \n",
    "\n",
    "Note that loading the topics generated in a different script, can be used to predict topics in new documents using the `TopicPredictor` object, as presented in the example below. The \"top topic\" per year is then computed by how frequently these topics were predicted for each paper of that particular year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load topics \n",
    "with open(os.path.join(NEURIPS_ANALYSIS_DATA_PATH, '3grams_topics.json'), 'r') as f:\n",
    "    topics = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_predictor = TopicPredictor(topics)\n",
    "\n",
    "topics_per_year = {}\n",
    "\n",
    "year_topic_files = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for key, data in metadata.items():\n",
    "    year = data['year']\n",
    "    if year not in topics_per_year:\n",
    "        topics_per_year[year] = Counter()\n",
    "    \n",
    "    topic_prediction = topic_predictor.predict_topics(data['abstract'])\n",
    "    \n",
    "    year_topic_files[year][key] = [x[0] for x in sorted(topic_prediction.items(), key=lambda x: x[1], reverse=True) if x[1] > 0]\n",
    "    \n",
    "    if sum(topic_prediction.values()) > 0:\n",
    "        top_prediction = [x[0] for x in sorted(topic_prediction.items(), key=lambda x: x[1], reverse=True) if x[1] > 0][:5]\n",
    "        topics_per_year[year].update(top_prediction)\n",
    "\n",
    "        \n",
    "top3_topics_per_year = defaultdict(list)\n",
    "for year, topic_counter in topics_per_year.items():\n",
    "    top3_topics_per_year[year] = [x[0] for x in sorted(topic_counter.items(), key=lambda x: x[1], reverse=True)][:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "topic_2: ['loss_functions_deep', 'functions_deep_neural', 'optimized_stochastic_gradient', 'modern_deep_networks', 'stochastic_gradient_descent', 'gradient_descent_sgd', 'deep_neural_networks', 'high_dimensional_datasets', 'low_dimensional_structures', 'iterative_algorithm_based']\n",
      "------\n",
      "topic_8: ['sequential_monte_carlo', 'partially_observable_markov', 'observable_markov_decision', 'principled_framework_planning', 'provide_principled_framework', 'partially_observable_stochastic', 'markov_decision_processes', 'superposition-structured_dirty_statistical', 'problem_learning_control', 'high_dimensional_datasets']\n",
      "------\n",
      "topic_9: ['gaussian_graphical_models', 'paper_address_problem', 'linear_regression_models', 'dirichlet_allocation_lda', 'maximum_posteriori_map', 'address_problem_learning', 'problem_learning_structure', 'posteriori_map_assignment', 'study_problem_finding', 'directed_graphical_models']\n",
      "------\n",
      "topic_10: ['probabilistic_graphical_model', 'support_vector_machines', 'inference_graphical_models', 'nonlinear_dynamical_system', 'performs_probabilistic_inference', 'brain_performs_probabilistic', 'belief_propagation_lbp', 'vision_convolutional_neural', 'recurrent_neural_networks', 'natural_language_processing']\n",
      "------\n",
      "topic_15: ['simple_computationally_efficient', 'reinforcement_learning_psrl', 'sampling_reinforcement_learning', 'posterior_sampling_reinforcement', 'provably_efficient_learning', 'state_action_spaces', 'reinforcement_learning_algorithm', 'markov_decision_processes', 'superposition-structured_dirty_statistical', 'paper_concerns_problem']\n",
      "------\n",
      "topic_18: ['principal_component_analysis', 'machine_learning_problems', 'component_analysis_pca', 'range_machine_learning', 'spiked_covariance_model', 'dominant_singular_vectors', 'singular_vectors_matrix', 'low_dimensional_structures', 'high_dimensional_datasets', 'low-rank_tensor_decomposition']\n",
      "------\n",
      "topic_19: ['deep_reinforcement_learning', 'machine_learning_algorithms', 'learning_conditional_random', 'hyperparameters_machine_learning', 'long_standing_pursuit', 'standing_pursuit_machine', 'pursuit_machine_learning', 'tuning_hyperparameters_machine', 'deep_neural_networks', 'learning_structured_predictors']\n",
      "------\n",
      "topic_22: ['stochastic_gradient_methods', 'learning_signal_processing', 'machine_learning_signal', 'optimization_problems_machine', 'large-scale_optimization_problems', 'stochastic_gradient_descent', 'problems_machine_learning', 'graph-based_semi-supervised_learning', 'high_dimensional_datasets', 'contextual_bandits_learner']\n",
      "------\n",
      "topic_23: ['dirichlet_process_mixture', 'sequential_monte_carlo', 'approximate_inference_algorithms', 'machine_learning_markov', 'approximate_inference_algorithm', 'probabilistic_inference_algorithms', 'approximate_probabilistic_inference', 'contextual_bandits_learner', 'problem_learning_control', 'superposition-structured_dirty_statistical']\n",
      "------\n",
      "topic_35: ['convolutional_neural_networks', 'deep_convolutional_neural', 'multiple_kernel_learning', 'statistics_machine_learning', 'neural_networks_trained', 'neural_networks_achieved', 'large_class_loss', 'success_deep_convolutional', 'loss_function_data', 'machine_learning_practice']\n",
      "------\n",
      "topic_45: ['machine_learning_models', 'online_learning_algorithm', 'stochastic_convex_optimization', 'optimal_convergence_rates', 'joint_probability_distribution', 'optimization_algorithms_popular', 'maximum_posteriori_map', 'finding_maximum_posteriori', 'max-product_belief_propagation', 'posteriori_map_assignment']\n",
      "------\n",
      "topic_52: ['deep_neural_networks', 'convolutional_neural_network', 'neural_networks_trained', 'neural_network_model', 'key_goal_artificial', 'goal_artificial_general', 'artificial_general_intelligence', 'neural_networks_received', 'based_optimization_method', 'stochastic_gradient_descent']\n"
     ]
    }
   ],
   "source": [
    "top_topics = set()\n",
    "for year, top3_topics in top3_topics_per_year.items():\n",
    "    top_topics.update(top3_topics)\n",
    "sorted_top_topics = sorted(top_topics, key=lambda x: int(x.split('_')[-1]), reverse=False)  # mini hack to sort by topic number\n",
    "\n",
    "for t in sorted_top_topics:\n",
    "    print(f'------\\n{t}: {topics[t]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming topics\n",
    "\n",
    "Visualy reviewing the 3-grams lists for each topic, most of them are easy to associate to a particular type of research line (e.g. `Topic 2` pairs well with optimization methods for deep learning), though other topics are a little bit harder (e.g. `Topic 10` has graphical models, SVMs, neural networks, and NLP in it). Given that these topic terms are indeed ranked within each topic, I used the top 5 to decide on a name for the hard cases (e.g. `Topic 10` top 5 terms are most associated to `Probabilistic Graphical Models`, so that's the one I used).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009 --> ['probabilistic graphical models', 'bayesian methods', 'probabilistic graphical models (inference)']\n",
      "2010 --> ['probabilistic graphical models', 'reinforcement learning', 'neural networks']\n",
      "2011 --> ['probabilistic graphical models (inference)', 'neural networks', 'ML optimization problems (gradients)']\n",
      "2012 --> ['bayesian inference algorithms', 'probabilistic graphical models', 'markov decision processes']\n",
      "2013 --> ['markov decision processes', 'matrix decomposition', 'reinforcement learning']\n",
      "2014 --> ['probabilistic graphical models (inference)', 'neural networks', 'matrix decomposition']\n",
      "2015 --> ['deep learning (optimization)', 'deep learning (models)', 'neural networks']\n",
      "2016 --> ['deep learning (optimization)', 'deep learning (models)', 'deep reinforcement learning']\n",
      "2017 --> ['deep learning (optimization)', 'deep learning (models)', 'deep reinforcement learning']\n",
      "2018 --> ['deep learning (optimization)', 'deep learning (models)', 'deep reinforcement learning']\n",
      "2019 --> ['deep learning (optimization)', 'deep learning (models)', 'deep reinforcement learning']\n"
     ]
    }
   ],
   "source": [
    "topic_mapping = {\n",
    "    'topic_2': 'deep learning (optimization)',\n",
    "    'topic_8': 'markov decision processes',\n",
    "    'topic_9': 'probabilistic graphical models',\n",
    "    'topic_10': 'probabilistic graphical models (inference)',\n",
    "    'topic_15': 'reinforcement learning',\n",
    "    'topic_18': 'matrix decomposition',\n",
    "    'topic_19': 'deep reinforcement learning',\n",
    "    'topic_22': 'ML optimization problems (gradients)',\n",
    "    'topic_23': 'bayesian inference algorithms',\n",
    "    'topic_35': 'neural networks',\n",
    "    'topic_45': 'bayesian methods',\n",
    "    'topic_52': 'deep learning (models)'\n",
    "}\n",
    "topic_mapping_snake = {\n",
    "    'topic_2': 'deep_learning_optimization',\n",
    "    'topic_8': 'markov_decision processes',\n",
    "    'topic_9': 'probabilistic_graphical_models',\n",
    "    'topic_10': 'probabilistic_graphical_models_inference',\n",
    "    'topic_15': 'reinforcement_learning',\n",
    "    'topic_18': 'matrix_decomposition',\n",
    "    'topic_19': 'deep_reinforcement_learning',\n",
    "    'topic_22': 'ML_optimization_problems_gradients',\n",
    "    'topic_23': 'bayesian_inference_algorithms',\n",
    "    'topic_35': 'neural_networks',\n",
    "    'topic_45': 'bayesian_methods',\n",
    "    'topic_52': 'deep_learning_models'\n",
    "}\n",
    "\n",
    "for year, top_topics in sorted(top3_topics_per_year.items(), key=lambda x: x[0]):\n",
    "    print(f'{year} --> {[topic_mapping.get(t) for t in top_topics]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institutions networks per topic\n",
    "\n",
    "In this section, an institutions network is built using papers associated to the top 3 topics each year. \n",
    "\n",
    "Note that graphs are created as `directed` in this example (unlike the other institutions network example) so that the Hirearchical Edge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_counter = Counter()\n",
    "for file, lines in list(file_lines.items()):\n",
    "    file_institutions = institutions.get_file_institutions(lines)\n",
    "    unique_file_institutions = list(set(file_institutions))\n",
    "    inst_counter.update(unique_file_institutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b583aa1a6df40b282a933b7f41ba433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "year: 2009\n",
      "------\n",
      "\n",
      "Topic 1: probabilistic graphical models\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 9\n",
      "Number of edges: 13\n",
      "Average in degree:   1.4444\n",
      "Average out degree:   1.4444\n",
      "\n",
      "Topic 2: bayesian methods\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 11\n",
      "Number of edges: 17\n",
      "Average in degree:   1.5455\n",
      "Average out degree:   1.5455\n",
      "\n",
      "Topic 3: probabilistic graphical models (inference)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 3\n",
      "Number of edges: 3\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "------\n",
      "year: 2010\n",
      "------\n",
      "\n",
      "Topic 1: probabilistic graphical models\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 7\n",
      "Number of edges: 7\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "\n",
      "Topic 2: reinforcement learning\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 3\n",
      "Number of edges: 4\n",
      "Average in degree:   1.3333\n",
      "Average out degree:   1.3333\n",
      "\n",
      "Topic 3: neural networks\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 4\n",
      "Number of edges: 4\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "------\n",
      "year: 2011\n",
      "------\n",
      "\n",
      "Topic 1: probabilistic graphical models (inference)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 6\n",
      "Number of edges: 6\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "\n",
      "Topic 2: neural networks\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 2\n",
      "Number of edges: 2\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "\n",
      "Topic 3: ML optimization problems (gradients)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 6\n",
      "Number of edges: 6\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "------\n",
      "year: 2012\n",
      "------\n",
      "\n",
      "Topic 1: bayesian inference algorithms\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 9\n",
      "Number of edges: 9\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "\n",
      "Topic 2: probabilistic graphical models\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 8\n",
      "Number of edges: 9\n",
      "Average in degree:   1.1250\n",
      "Average out degree:   1.1250\n",
      "\n",
      "Topic 3: markov decision processes\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 7\n",
      "Number of edges: 7\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "------\n",
      "year: 2013\n",
      "------\n",
      "\n",
      "Topic 1: markov decision processes\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 12\n",
      "Number of edges: 16\n",
      "Average in degree:   1.3333\n",
      "Average out degree:   1.3333\n",
      "\n",
      "Topic 2: matrix decomposition\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 11\n",
      "Number of edges: 16\n",
      "Average in degree:   1.4545\n",
      "Average out degree:   1.4545\n",
      "\n",
      "Topic 3: reinforcement learning\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 12\n",
      "Number of edges: 15\n",
      "Average in degree:   1.2500\n",
      "Average out degree:   1.2500\n",
      "------\n",
      "year: 2014\n",
      "------\n",
      "\n",
      "Topic 1: probabilistic graphical models (inference)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 10\n",
      "Number of edges: 13\n",
      "Average in degree:   1.3000\n",
      "Average out degree:   1.3000\n",
      "\n",
      "Topic 2: neural networks\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 14\n",
      "Number of edges: 14\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "\n",
      "Topic 3: matrix decomposition\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 9\n",
      "Number of edges: 19\n",
      "Average in degree:   2.1111\n",
      "Average out degree:   2.1111\n",
      "------\n",
      "year: 2015\n",
      "------\n",
      "\n",
      "Topic 1: deep learning (optimization)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 18\n",
      "Number of edges: 27\n",
      "Average in degree:   1.5000\n",
      "Average out degree:   1.5000\n",
      "\n",
      "Topic 2: deep learning (models)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 21\n",
      "Number of edges: 31\n",
      "Average in degree:   1.4762\n",
      "Average out degree:   1.4762\n",
      "\n",
      "Topic 3: neural networks\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 11\n",
      "Number of edges: 11\n",
      "Average in degree:   1.0000\n",
      "Average out degree:   1.0000\n",
      "------\n",
      "year: 2016\n",
      "------\n",
      "\n",
      "Topic 1: deep learning (optimization)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 23\n",
      "Number of edges: 36\n",
      "Average in degree:   1.5652\n",
      "Average out degree:   1.5652\n",
      "\n",
      "Topic 2: deep learning (models)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 28\n",
      "Number of edges: 42\n",
      "Average in degree:   1.5000\n",
      "Average out degree:   1.5000\n",
      "\n",
      "Topic 3: deep reinforcement learning\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 18\n",
      "Number of edges: 24\n",
      "Average in degree:   1.3333\n",
      "Average out degree:   1.3333\n",
      "------\n",
      "year: 2017\n",
      "------\n",
      "\n",
      "Topic 1: deep learning (optimization)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 26\n",
      "Number of edges: 41\n",
      "Average in degree:   1.5769\n",
      "Average out degree:   1.5769\n",
      "\n",
      "Topic 2: deep learning (models)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 29\n",
      "Number of edges: 45\n",
      "Average in degree:   1.5517\n",
      "Average out degree:   1.5517\n",
      "\n",
      "Topic 3: deep reinforcement learning\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 23\n",
      "Number of edges: 48\n",
      "Average in degree:   2.0870\n",
      "Average out degree:   2.0870\n",
      "------\n",
      "year: 2018\n",
      "------\n",
      "\n",
      "Topic 1: deep learning (optimization)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 43\n",
      "Number of edges: 57\n",
      "Average in degree:   1.3256\n",
      "Average out degree:   1.3256\n",
      "\n",
      "Topic 2: deep learning (models)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 49\n",
      "Number of edges: 69\n",
      "Average in degree:   1.4082\n",
      "Average out degree:   1.4082\n",
      "\n",
      "Topic 3: deep reinforcement learning\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 38\n",
      "Number of edges: 50\n",
      "Average in degree:   1.3158\n",
      "Average out degree:   1.3158\n",
      "------\n",
      "year: 2019\n",
      "------\n",
      "\n",
      "Topic 1: deep learning (optimization)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 47\n",
      "Number of edges: 74\n",
      "Average in degree:   1.5745\n",
      "Average out degree:   1.5745\n",
      "\n",
      "Topic 2: deep learning (models)\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 53\n",
      "Number of edges: 90\n",
      "Average in degree:   1.6981\n",
      "Average out degree:   1.6981\n",
      "\n",
      "Topic 3: deep reinforcement learning\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 48\n",
      "Number of edges: 69\n",
      "Average in degree:   1.4375\n",
      "Average out degree:   1.4375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def subset_data(year, topic, year_topic_files):\n",
    "    topic_files = year_topic_files[year]\n",
    "    keys = []\n",
    "    for key, topics_prediction in topic_files.items():\n",
    "        if topic in topics_prediction:\n",
    "            keys.append(key) \n",
    "    return keys\n",
    "\n",
    "            \n",
    "graphs_per_topic = {}\n",
    "for year, topics_per_year in tqdm(sorted(top3_topics_per_year.items(), key=lambda x: x[0])):\n",
    "    print(f'------\\nyear: {year}\\n------')    \n",
    "    if year not in graphs_per_topic:\n",
    "        graphs_per_topic[year] = {}\n",
    "    for idx, topic in enumerate(topics_per_year):\n",
    "        keys_filter = subset_data(year, topic, year_topic_files)\n",
    "        graphs_per_topic[year][topic], _ = institutions_graph.build_institutions_graph(file_lines, metadata, inst_counter, freq=5, year=year, keys_filter=keys_filter, directed=True)\n",
    "        print(f'\\nTopic {idx+1}: {topic_mapping[topic]}')\n",
    "        print(nx.info(graphs_per_topic[year][topic]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08145132d6542cbb6d51ba9fed4ab16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder = 'heb_files'\n",
    "\n",
    "for year, topics_per_year in tqdm(sorted(top3_topics_per_year.items(), key=lambda x: x[0])):\n",
    "    for idx, topic in enumerate(topics_per_year):\n",
    "        file_name = f'{year}-topic_{idx+1}-{topic_mapping_snake[topic]}_graph.json'\n",
    "        institutions_graph.dump_to_d3js_heb(\n",
    "            graphs_per_topic[year][topic], os.path.join(NEURIPS_ANALYSIS_DATA_PATH, folder, file_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network analysis \n",
    "\n",
    "Using this data, there's a wide range of questions that could be answered. \n",
    "\n",
    "For example, which institutions have co-authored papers the most over the top 3 topics per year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('university of washington-microsoft research', {2015, 2016, 2019}),\n",
       " ('university of texas at austin-microsoft research', {2013, 2019}),\n",
       " ('carnegie mellon university-bosch center for artiﬁcial intelligence',\n",
       "  {2018, 2019}),\n",
       " ('university of cambridge-deepmind', {2017, 2019}),\n",
       " ('princeton university-mit', {2014, 2017}),\n",
       " ('mit-microsoft research', {2009, 2017}),\n",
       " ('google research-google brain', {2016, 2018}),\n",
       " ('university of california berkeley-university of texas at austin',\n",
       "  {2009, 2014}),\n",
       " ('georgia institute of technology-carnegie mellon university', {2011, 2014}),\n",
       " ('purdue university-microsoft research', {2009, 2010}),\n",
       " ('microsoft research-kaist', {2009, 2011})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_per_year = defaultdict(set)\n",
    "\n",
    "for year, topics_per_year in top3_topics_per_year.items():\n",
    "    for topic in topics_per_year:\n",
    "        for edge in graphs_per_topic[year][topic].edges():\n",
    "            if len(set(edge)) > 1:\n",
    "                e = f'{edge[0]}-{edge[1]}'\n",
    "                e_r = f'{edge[1]}-{edge[0]}'\n",
    "                if e_r in edges_per_year:\n",
    "                    continue\n",
    "                edges_per_year[e].add(year)\n",
    "[x for x in sorted(edges_per_year.items(), key=lambda x: len(x[1]), reverse=True) if len(x[1]) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
